{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshatsanghvi211103/CVIT_WORKSHOP/blob/main/Day2_Session_1_Task_2_Line_Word_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOJ9CD9xZo54"
      },
      "source": [
        "# CVIT Orientation : Problem Statement\n",
        "\n",
        "Line & Word level segementation in documents is an important task for extracting text ( OCR ) task . \n",
        "\n",
        "In the following case , we take a look at different printed documents and try to extract charecter line segment and word level arguments. \n",
        "\n",
        "References : \n",
        "1.https://pyimagesearch.com/2021/04/28/opencv-morphological-operations/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z9i8u-eZ9Bv"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import cv2 \n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1MaQQvK0deG",
        "outputId": "13c87958-e379-48da-bf5b-561086d9c78c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data\n",
            "Akshat.pptx\n",
            "Colab Notebooks\n",
            "images\n",
            "transcript.pdf\n",
            "./drive/MyDrive/Colab Notebooks:\n",
            "Day 1 Session 1.ipynb\n",
            "Day 1 Session 2 Barcode Detection and Scanning Notebook.ipynb\n",
            "Day 2 Session 1 Task-1.ipynb\n",
            "Day2 Session 1 Task-2 Line_Word_Segmentation.ipynb\n",
            "Day 3 Session 1 CV_Workshop_Optimisation_2.ipynb\n",
            "Day 3 Session 2 Windowing-demo.ipynb\n",
            "Day 4 Session 1 Task-1 CVIT_intro_to_pymeshlab.ipynb\n",
            "Day 4 Session 1 Task-2 Open3D.ipynb\n",
            "Session 2 Day 2 - Cheque number reader\n",
            "Solution of Day 1 Session 2 of Barcode Detection and Reading.ipynb\n",
            "Solution - The Copy of CV_Workshop_Optimisation_2.ipynb\n",
            "./sample_data:\n",
            "anscombe.json\n",
            "california_housing_test.csv\n",
            "california_housing_train.csv\n",
            "mnist_test.csv\n",
            "mnist_train_small.csv\n"
          ]
        }
      ],
      "source": [
        "!ls -R | grep s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pbm0WuIjeNGK"
      },
      "outputs": [],
      "source": [
        "PATH_MEDIUM = '/content/test_tamil.jpg'\n",
        "PATH_LINE_EXAMPLE = '/content/test_sanskrit.png'\n",
        "PATH_HARDEST = '/content/test.jpeg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPuP4OB2_r1g"
      },
      "outputs": [],
      "source": [
        "# Idea is to leverage different morphological filters\n",
        "def textdilationElementWise(binary_image,iterations=3):\n",
        "  '''\n",
        "  binary image : text = 1 bg = 0 \n",
        "  '''\n",
        "  # Small local kernel that tickens the existing text more closely\n",
        "  text_kernel = np.ones((3,3))\n",
        "  dilated_image = cv2.dilate(binary_image,text_kernel,iterations)\n",
        "  return dilated_image\n",
        "\n",
        "\n",
        "def rectangledilation(binary_image,H,W,iterations=3): # note that iterations have already been defined\n",
        "  '''\n",
        "  binary image : text = 1 bg = 0 \n",
        "  '''\n",
        "  # Small local kernel that tickens the existing text more closely\n",
        "  rectange_kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(H,W))\n",
        "  dilated_image = cv2.dilate(binary_image,rectange_kernel,iterations)\n",
        "  return dilated_image\n",
        "\n",
        "def erosionOperation(binary_image,H,W,iterations=3):\n",
        "  # Small local kernel that erodes vertically\n",
        "  rectange_kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(H,W))\n",
        "  eroded_image = cv2.erode(binary_image,rectange_kernel,iterations)\n",
        "  return eroded_image\n",
        "\n",
        "def crossErosion(binary_image,iterations=2): # important\n",
        "  cross_kernel= cv2.getStructuringElement(cv2.MORPH_CROSS,(5,5))\n",
        "  cross_eroded_image = cv2.erode(binary_image,cross_kernel,iterations)\n",
        "  return cross_eroded_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GTiDLHfY581",
        "outputId": "1c1f7f6a-bd4e-4f37-f599-1bfdee09f17c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjGRsEI9ebgT"
      },
      "outputs": [],
      "source": [
        "\n",
        "def binarize_and_word_detect_contours(image_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    \n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # removing noise is very important, as small noise may also be considered as text, which may detect the noise with 2 adjacent words as a single word\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0) # removing gaussian noise\n",
        "    # Apply image denoising\n",
        "    denoised = cv2.fastNlMeansDenoising(blurred, None, h=10, templateWindowSize=7, searchWindowSize=21) # advanced denoising\n",
        "    \n",
        "    # Apply binary thresholding\n",
        "    _, binary = cv2.threshold(denoised, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    cv2_imshow(binary)\n",
        "    # text dilation \n",
        "    print('Thicker text') # so that we can make them into one contour\n",
        "\n",
        "    ##### THIS STEP IS VERY IMPORTANT #####\n",
        "    thickTextDocument = textdilationElementWise(255-binary,iterations=5) # 255 - binary will invert the image\n",
        "    cv2_imshow(thickTextDocument)\n",
        "\n",
        "    print('Word level dilation')\n",
        "    wordTextDocument = rectangledilation(thickTextDocument,H=7,W=3,iterations=3)\n",
        "    cv2_imshow(wordTextDocument)\n",
        "\n",
        "    # print('Dilation Operation to join cuts within word blobs')\n",
        "    # closeDocument = textdilationElementWise(wordTextDocument,iterations=3)\n",
        "    # cv2_imshow(closeDocument)\n",
        "\n",
        "    # print('Cross Kernel Erosion : To further split interline blobs')\n",
        "    # crossErodedDocument = crossErosion(closeDocument,iterations=3)\n",
        "    # cv2_imshow(crossErodedDocument)\n",
        "\n",
        "    # Find contours in the binary image\n",
        "    contours, _ = cv2.findContours(wordTextDocument,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Filter out the extremely small boxes based on area threshold \n",
        "    areaThreshold = 5\n",
        "    finalContours = [ c for c in contours if cv2.contourArea(c)>areaThreshold ]\n",
        "    \n",
        "    # Draw contours on the original image\n",
        "    image_with_contours = cv2.drawContours(image.copy(),finalContours, -1, (0, 255, 0), 2)\n",
        "    image_with_boxes = image.copy()\n",
        "    for contour in finalContours:\n",
        "      # Find the bounding box coordinates\n",
        "      x, y, w, h = cv2.boundingRect(contour)\n",
        "      # Draw the bounding box on the image\n",
        "      cv2.rectangle(image_with_boxes, (x, y), (x + w, y + h), (0,0,255),3)\n",
        "\n",
        "    \n",
        "    # Display the original image and the image with contours\n",
        "    print('Image With Contours')\n",
        "    cv2_imshow(image_with_contours)\n",
        "\n",
        "    # Display the original image and the image with contours\n",
        "    print('Image With Boxes')\n",
        "    cv2_imshow(image_with_boxes)\n",
        "\n",
        "    # Save them in the directory \n",
        "    _,imgName = os.path.split(image_path)\n",
        "    cv2.imwrite('wordlevel_contours_'+imgName,image_with_contours)\n",
        "    cv2.imwrite('wordlevel_boxes_'+imgName,image_with_boxes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zv72eWTtZHhZ",
        "outputId": "ea9d17d0-9e0c-4f28-ad53-3e6a5ea911c8"
      },
      "outputs": [],
      "source": [
        "# Usage example\n",
        "binarize_and_word_detect_contours(PATH_HARDEST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnFBJesV_Qv_"
      },
      "outputs": [],
      "source": [
        "def binarize_and_line_detect_contours(image_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    \n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    # Apply image denoising\n",
        "    denoised = cv2.fastNlMeansDenoising(blurred, None, h=10, templateWindowSize=7, searchWindowSize=21)\n",
        "    \n",
        "    # Apply binary thresholding\n",
        "    _, binary = cv2.threshold(denoised, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    cv2_imshow(binary)\n",
        "    # text dilation \n",
        "    print('Thicker text')\n",
        "    thickTextDocument = textdilationElementWise(255-binary,iterations=5)\n",
        "    cv2_imshow(thickTextDocument)\n",
        "\n",
        "    print('Line Level Dilation')\n",
        "\n",
        "    # search the phrases\n",
        "    dilatation_type = cv2.MORPH_RECT\n",
        "    horizontal_dilatation = 5 \n",
        "    vertical_dilatation = 0\n",
        "    element = cv2.getStructuringElement(dilatation_type, (2*horizontal_dilatation + 1, 2*vertical_dilatation+1), (horizontal_dilatation, vertical_dilatation))\n",
        "    dilatation_thresh = cv2.dilate(thickTextDocument,element,iterations=1)\n",
        "\n",
        "    # Fill\n",
        "    filled_tresh = dilatation_thresh.copy()\n",
        "    contours, hierarchy = cv2.findContours(dilatation_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "    for cnt in contours:\n",
        "        cv2.drawContours(filled_tresh, [cnt], -1, 255, cv2.FILLED)\n",
        "    \n",
        "\n",
        "    # Connect these disconnected blobs further \n",
        "    print('Line level dilation')\n",
        "    lineTextDocument = rectangledilation(filled_tresh,H=31,W=1,iterations=1)\n",
        "    cv2_imshow(lineTextDocument)\n",
        "\n",
        "    # Cross Filter : Erosion \n",
        "    lineTextDocument = crossErosion(lineTextDocument,iterations=10)\n",
        "    print('Line erosion')\n",
        "    cv2_imshow(lineTextDocument)\n",
        "\n",
        "    # Find contours in the binary image\n",
        "    contours, _ = cv2.findContours(lineTextDocument,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  \n",
        "    # Filter out the extremely small boxes based on area threshold \n",
        "    areaThreshold = 1000\n",
        "    finalContours = [ c for c in contours if cv2.contourArea(c)>areaThreshold ]\n",
        "    \n",
        "    # Draw contours on the original image\n",
        "    image_with_contours = cv2.drawContours(image.copy(),finalContours, -1, (255,0,0),3)\n",
        "    image_with_boxes = image.copy()\n",
        "\n",
        "    for contour in finalContours:\n",
        "      # Find the bounding box coordinates\n",
        "      x, y, w, h = cv2.boundingRect(contour)\n",
        "      # Draw the bounding box on the image\n",
        "      cv2.rectangle(image_with_boxes, (x, y), (x + w, y + h), (0,0,255),3)\n",
        "\n",
        "    \n",
        "    # Display the original image and the image with contours\n",
        "    print('Image With Contours')\n",
        "    cv2_imshow(image_with_contours)\n",
        "\n",
        "    # Display the original image and the image with contours\n",
        "    print('Image With Boxes')\n",
        "    cv2_imshow(image_with_boxes)\n",
        "\n",
        "    # # Save them in the directory \n",
        "    # _,imgName = os.path.split(image_path)\n",
        "    # cv2.imwrite('linelevel_contours_'+imgName,image_with_contours)\n",
        "    # cv2.imwrite('linelevel_boxes_'+imgName,image_with_boxes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "APiTKw2K1Uy0",
        "outputId": "114203e5-8ded-4361-b878-03579773191a"
      },
      "outputs": [],
      "source": [
        "# Usage example ( easy - less dense example )\n",
        "binarize_and_line_detect_contours(PATH_MEDIUM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Bwjv2zbgC09"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}